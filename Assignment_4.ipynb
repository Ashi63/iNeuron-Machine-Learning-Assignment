{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af86174",
   "metadata": {},
   "source": [
    "### 1. What are the key tasks involved in getting ready to work with machine learning modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea348f6",
   "metadata": {},
   "source": [
    "- Before working with machine learning modeling, there are several key tasks that need to be accomplished. These tasks include:\n",
    "\n",
    "    - Defining the problem: The first step in any machine learning project is to clearly define the problem that needs to be solved. This involves understanding the business problem, defining the scope of the project, and identifying the desired outcomes.\n",
    "\n",
    "    - Data collection: The next step is to collect the data required to solve the problem. This may involve accessing existing data sources or collecting new data through surveys, sensors, or other means. It is important to ensure that the data collected is relevant, accurate, and representative of the problem domain.\n",
    "\n",
    "    - Data preparation: Once the data is collected, it needs to be cleaned, transformed, and prepared for analysis. This may involve tasks such as removing missing values, handling outliers, scaling the data, and splitting the data into training and testing sets.\n",
    "\n",
    "    - Feature engineering: Feature engineering involves selecting and transforming the most relevant features or variables in the data to create new features that may be more predictive of the target variable. This may involve tasks such as feature selection, feature scaling, or creating new features through domain knowledge.\n",
    "\n",
    "    - Model selection: The next step is to select an appropriate model that is suited to the problem at hand. This may involve selecting from a range of models, such as linear regression, decision trees, or neural networks, based on their strengths and weaknesses.\n",
    "\n",
    "    - Model training: Once the model is selected, it needs to be trained on the prepared data. This involves fitting the model to the training data and adjusting the model parameters to optimize its performance.\n",
    "\n",
    "    - Model evaluation: After training the model, it needs to be evaluated on the test data to assess its performance. This involves measuring metrics such as accuracy, precision, recall, and F1 score to determine how well the model is able to predict the target variable.\n",
    "\n",
    "    - Model deployment: Finally, the model needs to be deployed in a production environment where it can be used to make predictions on new data. This may involve integrating the model into a software application or a web service, and monitoring its performance over time.\n",
    "    - Model monitoring is the process of tracking the performance and behavior of a machine learning model over time, once it has been deployed in a production environment. It is an important part of the model lifecycle, as it allows organizations to ensure that their models are performing as expected and identify any issues or changes that may affect their performance.Some of the key tasks involved in model monitoring include:Collecting data, Defining metrics, Setting up alerts, Performing periodic evaluations, Monitoring for concept drift, Updating the model: This may involve retraining the model, or using techniques such as online learning to update it in real-time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a3066",
   "metadata": {},
   "source": [
    "### 2. What are the different forms of data used in machine learning? Give a specific example for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31560e83",
   "metadata": {},
   "source": [
    "- There are three main types of data used in machine learning:\n",
    "\n",
    "    - Numerical data: Numerical data is represented as numbers and can be further categorized as discrete or continuous. Discrete numerical data refers to a finite set of values, while continuous numerical data refers to an infinite set of values. Examples of numerical data include age, weight, and temperature.\n",
    "Example: A machine learning algorithm could be trained to predict a person's weight based on their height, age, and gender.\n",
    "\n",
    "    - Categorical data: Categorical data represents variables that take on a limited set of values or categories. These variables can be nominal or ordinal. Nominal variables do not have an inherent order, while ordinal variables have a natural order. Examples of categorical data include gender, race, and education level.\n",
    "Example: A machine learning algorithm could be trained to predict the likelihood of a customer making a purchase based on their age, gender, and education level.\n",
    "\n",
    "    - Text data: Text data refers to data that is represented as strings of characters, such as written language or social media posts. Text data can be used to extract features such as sentiment, topics, and keywords.\n",
    "Example: A machine learning algorithm could be trained to classify text messages as spam or not spam based on the words and phrases used in the message.\n",
    "\n",
    "In addition to these three main types of data, there are also other types of data that can be used in machine learning, such as image data and time-series data. Image data consists of pixels that can be used to represent visual information, while time-series data represents data that changes over time, such as stock prices or weather patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba78bf",
   "metadata": {},
   "source": [
    "### 3. Distinguish:\n",
    "\n",
    "1. Numeric vs. categorical attributes\n",
    "\n",
    "2. Feature selection vs. dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3aa4f7",
   "metadata": {},
   "source": [
    "1. Numeric vs. categorical attributes\n",
    "\n",
    "    - Numeric attributes are those attributes that take on numerical values, while categorical attributes are those that take on values from a set of categories or labels.\n",
    "\n",
    "    - Numeric attributes are further divided into two types: continuous and discrete. Continuous numeric attributes are those that can take on any value within a range, while discrete numeric attributes can only take on specific values within a range. Examples of continuous numeric attributes include height, weight, temperature, and age, while examples of discrete numeric attributes include shoe size, number of siblings, and number of pets.\n",
    "\n",
    "    - Categorical attributes can be nominal or ordinal. Nominal categorical attributes have no inherent order, while ordinal categorical attributes have a natural order. Examples of nominal categorical attributes include gender, race, and country of origin, while examples of ordinal categorical attributes include education level and income level.\n",
    "\n",
    "The choice of whether to use numeric or categorical attributes in a machine learning model depends on the nature of the problem and the available data. Numeric attributes are more suitable for problems where the magnitude of the attribute is important, such as predicting the price of a house based on its size and location. Categorical attributes are more suitable for problems where the presence or absence of a particular attribute is important, such as predicting whether a customer will buy a product based on their age, gender, and income level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7e7d8",
   "metadata": {},
   "source": [
    "2. Feature selection vs. dimensionality reduction\n",
    "    - Feature selection and dimensionality reduction are two techniques used in machine learning to reduce the number of input variables in a dataset. However, they differ in their approach and goals.\n",
    "\n",
    "    - Feature selection is the process of selecting a subset of the most relevant features from a larger set of features. The goal of feature selection is to reduce the dimensionality of the dataset while retaining the most important features that contribute the most to the predictive power of the model. Feature selection can be done manually by domain experts or automatically by algorithms. Feature selection techniques include forward selection, backward elimination, and principal component analysis (PCA).\n",
    "\n",
    "    - Dimensionality reduction, on the other hand, is the process of transforming a high-dimensional dataset into a lower-dimensional space while preserving the most important information in the data. The goal of dimensionality reduction is to simplify the dataset by eliminating redundant and irrelevant features that do not contribute much to the overall variance of the data. Dimensionality reduction techniques include PCA, t-SNE, and autoencoders.\n",
    "\n",
    "The main difference between feature selection and dimensionality reduction is that feature selection preserves the original features of the dataset but discards the less important ones, while dimensionality reduction creates a new set of features that are a combination of the original features. Feature selection is useful when the number of features is relatively small, while dimensionality reduction is more effective when dealing with high-dimensional datasets where the number of features is much larger than the number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d391d19",
   "metadata": {},
   "source": [
    "### 4. Make quick notes on any two of the following:\n",
    "\n",
    "1. The histogram\n",
    "\n",
    "2. Use a scatter plot\n",
    "\n",
    "3. PCA (Personal Computer Aid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51692f63",
   "metadata": {},
   "source": [
    "1. The histogram\n",
    "- A histogram is a graphical representation of the distribution of a dataset. It consists of a series of bars or rectangles, where the area of each bar represents the frequency of occurrence of a range of values within the dataset.\n",
    "\n",
    "- In a histogram, the x-axis represents the range of values in the dataset, divided into intervals called bins. The y-axis represents the frequency or count of values that fall within each bin. The width of each bin and the height of each bar represent the size of the range of values and the number of values that fall within that range, respectively.\n",
    "\n",
    "Histograms are commonly used in data analysis to visualize the distribution of a dataset, especially when the dataset is large and complex. They can provide insights into the shape, central tendency, and variability of the data, and help identify any outliers or anomalies. Histograms are widely used in various fields, including statistics, economics, biology, and engineering, to name a few."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3045a234",
   "metadata": {},
   "source": [
    "### 5. Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da74e3d",
   "metadata": {},
   "source": [
    "Investigating data is necessary to gain insights and understanding of the information contained within it. Data can be complex and vast, and without investigation, important patterns, trends, and relationships within the data may go unnoticed. Data exploration involves visualizing, summarizing, and analyzing data to extract meaningful information and generate hypotheses for further investigation.\n",
    "\n",
    "- Both qualitative and quantitative data require exploration, but there may be differences in the techniques used to explore each type of data. Qualitative data, such as interviews or open-ended survey responses, may require a more subjective and interpretive approach to exploration. Researchers may need to read through and code qualitative data to identify themes and patterns. Qualitative data may also be explored using visualizations, such as word clouds or network graphs, to identify relationships between themes or concepts.\n",
    "\n",
    "- Quantitative data, such as numerical or categorical data, may be explored using descriptive statistics, such as measures of central tendency and variability, as well as visualizations, such as histograms or box plots. Data exploration for quantitative data may also involve hypothesis testing and statistical modeling to identify relationships and make predictions.\n",
    "\n",
    "In summary, investigating data is crucial to uncovering patterns and relationships within the data that can inform decision-making and further investigation. While there may be differences in the techniques used to explore qualitative and quantitative data, both types of data require careful exploration and analysis to extract meaningful insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410a4f22",
   "metadata": {},
   "source": [
    "### 6. What are the various histogram shapes? What exactly are ‘bins'?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56afe621",
   "metadata": {},
   "source": [
    "There are several common shapes that histograms can take:\n",
    "\n",
    "- Normal Distribution: This is a symmetrical bell-shaped histogram, where the majority of the data falls in the middle, with fewer data points at the extremes.\n",
    "\n",
    "- Skewed Distribution: This is when the histogram is asymmetrical, with a long tail on one side. Positive skew means the tail is on the right side, and negative skew means the tail is on the left side.\n",
    "\n",
    "- Bimodal Distribution: This is when the histogram has two peaks, indicating that there are two distinct groups or modes in the data.\n",
    "\n",
    "- Uniform Distribution: This is when the histogram has roughly equal frequencies across all bins, indicating that there is no particular pattern in the data.\n",
    "\n",
    "Bins are the intervals into which the range of values in a dataset is divided. Each bin represents a range of values, and the height of the bar above the bin represents the frequency or count of values that fall within that range. Bins are essential for constructing histograms, as they determine the width of each bar and the range of values that each bar represents. Choosing the appropriate number and width of bins is critical to ensure that the histogram accurately represents the distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832dcb2f",
   "metadata": {},
   "source": [
    "### 7. How do we deal with data outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1e291",
   "metadata": {},
   "source": [
    "- Outliers are data points that are significantly different from other observations in the dataset, either in terms of their magnitude or in their relationship with other variables. Outliers can arise due to measurement errors, natural variability, or other reasons, and can have a significant impact on the analysis and modeling of data.\n",
    "\n",
    "- Here are some common methods for dealing with data outliers:\n",
    "\n",
    "    1. Removing outliers: One way to deal with outliers is to simply remove them from the dataset. However, this approach can be risky, as it may result in the loss of valuable information and can bias the analysis.\n",
    "\n",
    "    2. Transforming the data: Transforming the data using mathematical functions such as logarithms or square roots can help reduce the impact of outliers on the analysis. This approach can be useful for data that has a skewed distribution.\n",
    "\n",
    "    3. Winsorizing: Winsorizing involves replacing extreme values with less extreme values, such as the maximum or minimum value within a certain range. This approach can help preserve the data while reducing the impact of outliers.\n",
    "\n",
    "    4. Robust methods: Robust methods are statistical techniques that are designed to be less sensitive to outliers. Examples include median instead of mean, trimming, and M-estimators.\n",
    "\n",
    "    5. Treating outliers as a separate group: In some cases, outliers may be of particular interest and may be analyzed separately from the rest of the data.\n",
    "\n",
    "The choice of method depends on the nature of the data and the analysis goals. It is important to carefully consider the implications of each approach and to document any changes made to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67d018",
   "metadata": {},
   "source": [
    "### 8. What are the various central inclination measures? Why does mean vary too much from median in certain data sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55beaf65",
   "metadata": {},
   "source": [
    "Central tendency measures are statistical measures that describe the typical or central value of a set of data. The most common measures of central tendency are the mean, median, and mode.\n",
    "\n",
    "- The mean is the sum of all the data points divided by the number of data points. The median is the middle value of the data when the values are sorted in ascending or descending order. The mode is the value that occurs most frequently in the data.\n",
    "\n",
    "- When data is symmetric and normally distributed, the mean and median are generally close together. However, in skewed distributions, the mean and median can differ significantly.\n",
    "\n",
    "- For example, if a dataset has extreme values, outliers or skewness, the mean can be influenced by these values, leading to a significant difference between the mean and the median. In this case, the median may be a more appropriate measure of central tendency as it is less affected by outliers or extreme values.\n",
    "\n",
    "- Another reason for the difference between the mean and median is the presence of multiple modes in the data. In such cases, the mode may be a better measure of central tendency than the mean or median.\n",
    "\n",
    "In summary, the choice of a central tendency measure depends on the nature of the data and the research question. It is important to carefully consider the distribution of the data and the presence of outliers or other unusual features before choosing a measure of central tendency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1d496",
   "metadata": {},
   "source": [
    "### 9. Describe how a scatter plot can be used to investigate bivariate relationships. Is it possible to find outliers using a scatter plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf620461",
   "metadata": {},
   "source": [
    "A scatter plot is a graphical representation of the relationship between two variables. It is a two-dimensional plot where each point represents a pair of values for the two variables being compared. Scatter plots can be used to investigate bivariate relationships between two variables.\n",
    "\n",
    "Scatter plots are useful because they allow us to visualize patterns in the data and identify relationships between the variables. For example, if we plot height on the x-axis and weight on the y-axis, we can examine whether there is a positive or negative relationship between the two variables. If the points on the plot form a line that slopes upward from left to right, then there is a positive relationship between height and weight. If the points form a line that slopes downward from left to right, then there is a negative relationship.\n",
    "\n",
    "Scatter plots can also be used to identify outliers in the data. An outlier is an observation that is significantly different from other observations in the data set. Outliers can be identified visually in a scatter plot as points that are far away from the other points. However, it is important to remember that not all data points that appear to be outliers are necessarily incorrect or invalid. Sometimes outliers may be due to measurement error or other factors that need to be investigated further.\n",
    "\n",
    "In summary, scatter plots are a useful tool for investigating bivariate relationships between two variables and can be used to identify outliers in the data. However, it is important to carefully examine any outliers and determine whether they are due to measurement error or other factors before taking any further action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a076e0a",
   "metadata": {},
   "source": [
    "### 10. Describe how cross-tabs can be used to figure out how two variables are related."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31e615f",
   "metadata": {},
   "source": [
    "Cross-tabulation, also known as contingency tables or crosstabs, is a statistical technique used to examine the relationship between two categorical variables. It is a simple and effective way to summarize and visualize data and can be used to identify patterns and relationships between variables.\n",
    "\n",
    "- To create a cross-tabulation table, the two categorical variables of interest are placed in the rows and columns of the table, respectively. The cells in the table represent the number of observations that fall into each category of the two variables. For example, if we were interested in examining the relationship between gender and education level, the rows might represent gender (male or female) and the columns might represent education level (high school, college, graduate degree). The cells would then represent the number of observations for each combination of gender and education level.\n",
    "\n",
    "- Once the cross-tabulation table has been created, it can be used to examine the relationship between the two variables. This can be done by calculating the percentage of observations that fall into each cell or by calculating the percentage of observations in each row or column. These percentages can be used to identify patterns and relationships between the variables. For example, if we find that a higher percentage of males have graduate degrees compared to females, this would suggest that there may be a relationship between gender and education level.\n",
    "\n",
    "- Cross-tabulation tables can also be used to test for statistical significance between the variables using statistical tests such as the chi-squared test or Fisher's exact test. These tests can help determine whether the relationship between the variables is statistically significant or whether it may be due to chance.\n",
    "\n",
    "In summary, cross-tabulation tables are a useful tool for examining the relationship between two categorical variables. They can be used to identify patterns and relationships and to test for statistical significance between the variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
